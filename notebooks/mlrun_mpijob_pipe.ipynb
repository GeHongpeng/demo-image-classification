{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and run a distributed training pipeline\n",
    "\n",
    "In this notebook we will use **MLRun** to run all the functions we've written in the [mlrun-mpijob-classify](mlrun_mpijob_classify.ipynb) and [nuclio-serving-tf-images](nuclio-serving-tf-images.ipynb) in a **Kubeflow Pipeline**.\n",
    "\n",
    "**Kubeflow Pipelines** will supply the orchastration to run the pipeline, while **MLRun** will supply an easy interface to define the pipeline and lunch the serving function at the end.\n",
    "\n",
    "We will show how to:\n",
    "* Run remote functions from notebooks using `code_to_function`\n",
    "* Run saved functions from our DB using `import_function`\n",
    "* How to define and lunch a Kubeflow Pipeline\n",
    "* How to access the DB from the code and list the pipeline's entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_function, code_to_function, get_run_db, mount_v3io, mlconf, new_model_server, v3io_cred, import_function\n",
    "import os\n",
    " \n",
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/User/mlrun/examples'\n",
    "images_path = os.path.join(base_dir, 'images')\n",
    "model_name = 'cat_vs_dog_v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and define ML functions for our pipeline (utils, training, serving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `code_to_function` we parse the given python file and build a function from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-02-27 17:14:11,337 running build to add mlrun package, set with_mlrun=False to skip if its already in the image\n",
      "[mlrun] 2020-02-27 17:14:11,362 starting remote build, image: .mlrun/func-default-file-utils-latest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a function from the python source code\n",
    "# The code contains functions for data import and labeling \n",
    "utilsfn = code_to_function(name='file_utils', filename='../src/utils.py',\n",
    "                           image='mlrun/mlrun:latest', kind='job')\n",
    "\n",
    "# Add mount access to the function\n",
    "utilsfn.apply(mount_v3io())\n",
    "\n",
    "# Build the function image, so we can later deploy it as a job via kubeflow\n",
    "utilsfn.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-02-27 17:14:11,620 function spec saved to path: ../yaml/utils.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f59b501deb8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utilsfn.export('../yaml/utils.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `import_function` we import the horovod training function from our DB.  \n",
    "As we can see, all the function deployment parameters were saved, like Replicas, GPU Configuration, Mounts, Runtime and the code source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'mpijob',\n",
       " 'metadata': {'name': 'horovod-trainer',\n",
       "  'tag': 'latest',\n",
       "  'hash': 'ca9b2f2453afddcb69c1cc7360687249062abb96',\n",
       "  'project': 'default',\n",
       "  'updated': '2020-02-27T16:24:48.358216'},\n",
       " 'spec': {'command': '/User/demo-image-classification/src/horovod-training.py',\n",
       "  'args': [],\n",
       "  'image': 'mlrun/mpijob:latest',\n",
       "  'volumes': [{'flexVolume': {'driver': 'v3io/fuse',\n",
       "     'options': {'accessKey': '48bfe2e0-9870-4d11-9924-b20502a85363',\n",
       "      'container': 'users',\n",
       "      'subPath': '/admin'}},\n",
       "    'name': 'v3io'}],\n",
       "  'volume_mounts': [{'mountPath': '/User', 'name': 'v3io'}],\n",
       "  'env': [{'name': 'V3IO_API', 'value': ''},\n",
       "   {'name': 'V3IO_USERNAME', 'value': ''},\n",
       "   {'name': 'V3IO_ACCESS_KEY', 'value': ''}],\n",
       "  'description': '',\n",
       "  'replicas': 4,\n",
       "  'image_pull_policy': 'Always',\n",
       "  'build': {'commands': []}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the training function object from MLRun DB\n",
    "trainer_fn = import_function('db://horovod-trainer')\n",
    "# trainer_fn.deploy()\n",
    "trainer_fn.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `filename=<jupyter notebook file>` in the `new_model_server` we parse the given Jupyter Notebook and build our model server from it.\n",
    "\n",
    "> All the annotations given in the notebook will be parsed and saved to the function normally\n",
    "\n",
    "The model server will deploy the model given under `models={<model_name>:<model_file_path>}` as `model_class=<model_class_name>` .  \n",
    "Just like any other MLRun function we can set our environment variables, workers and add mounts.\n",
    "\n",
    "The model server will provide us with a `/<model_name>/predict` endpoint where we can query the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f59b4fd4f98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference function\n",
    "inference_function = new_model_server('tf-images-server', \n",
    "                                      filename='./nuclio-serving-tf-images.ipynb',\n",
    "                                      model_class='TFModel')\n",
    "inference_function.with_http(workers=2)\n",
    "inference_function.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we define the Kubeflow Pipeline to run our process.  \n",
    "MLRun helps us doing that by requiring us to only add `<fn>.as_step()` in order to turn our functions to a pipeline step for kubeflow.  All the parameters and inputs can be then set regularly and will be deployed as defined in the pipeline.  \n",
    "\n",
    "The pipeline order is defined by the following:\n",
    "* We can specify `<fn>.after(<previous fn>)`\n",
    "* We can specify that a function has a parameter or input, taken from a previous function.  \n",
    "  Ex: `models={'cat_vs_dog_v1': train.outputs['model']}` in the inference function definition, taking the model file from the training function.\n",
    "  \n",
    "Notice that you need to `log_artifact` in your function and write it's name in the function's `outputs` parameter to expose it to the pipeline for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_path = 'v3io:///users/admin/mlrun/kfp/{{workflow.uid}}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='Image classification training pipeline',\n",
    "    description='Shows how to use mlrun with horovod.'\n",
    ")\n",
    "def hvd_pipeline(\n",
    "    image_archive=      'http://iguazio-sample-data.s3.amazonaws.com/catsndogs.zip',\n",
    "    images_path =       '/User/mlrun/examples/images', \n",
    "    source_dir=         '/User/mlrun/examples/images/cats_n_dogs',\n",
    "    checkpoints_dir=    '/User/mlrun/examples/checkpoints',\n",
    "    model_path=         '/User/mlrun/examples/models/cats_n_dogs.h5',\n",
    "    model_name=         'cat_vs_dog_v1'\n",
    "):\n",
    "    open_archive = utilsfn.as_step(name='download',\n",
    "                                   handler='open_archive',\n",
    "                                   out_path=images_path,\n",
    "                                   params={'target_dir': images_path},\n",
    "                                   inputs={'archive_url': image_archive},\n",
    "                                   outputs=['content']).apply(mount_v3io())\n",
    "              \n",
    "    label = utilsfn.as_step(name='label',\n",
    "                            handler='categories_map_builder',\n",
    "                            out_path=images_path,\n",
    "                            params={'source_dir': source_dir},\n",
    "                            outputs=['categories_map',\n",
    "                                     'file_categories']).apply(mount_v3io()).after(open_archive)\n",
    "    \n",
    "    train = trainer_fn.as_step(name='train',\n",
    "                               params={'epochs': 1,\n",
    "                                       'checkpoints_dir': checkpoints_dir,\n",
    "                                       'model_path': model_path,\n",
    "                                       'data_path': source_dir},\n",
    "                               inputs={\n",
    "                                   'categories_map': label.outputs['categories_map'],\n",
    "                                   'file_categories': label.outputs['file_categories']},\n",
    "                               outputs=['model']).apply(v3io_cred())\n",
    "\n",
    "    # deploy the model using nuclio functions\n",
    "    deploy = inference_function.deploy_step(project='nuclio-serving', \n",
    "                                            models={model_name: train.outputs['model']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug generate the pipeline dsl\n",
    "kfp.compiler.Compiler().compile(hvd_pipeline, 'hvd_pipeline.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.cnyidfihnjsz.iguazio-cd0.com/pipelines/#/experiments/details/fd369e6b-77b5-427b-977f-4e66d395cc55\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.cnyidfihnjsz.iguazio-cd0.com/pipelines/#/runs/details/4fe69e52-d5b5-4aac-92e4-2da2971dd09e\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client(namespace='default-tenant')\n",
    "arguments = {}\n",
    "run_result = client.create_run_from_pipeline_func(hvd_pipeline, arguments, experiment_name='horovod1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the run db \n",
    "db = get_run_db().connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the DB with filter on workflow ID (only show this workflow) \n",
    "db.list_runs('', labels=f'workflow={run_result.run_id}').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
