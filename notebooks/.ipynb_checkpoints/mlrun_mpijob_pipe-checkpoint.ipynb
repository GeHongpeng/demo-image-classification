{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and run a distributed training pipeline\n",
    "\n",
    "In this notebook we will use **MLRun** to run all the functions we've written in the [mlrun-mpijob-classify](mlrun_mpijob_classify.ipynb) and [nuclio-serving-tf-images](nuclio-serving-tf-images.ipynb) in a **Kubeflow Pipeline**.\n",
    "\n",
    "**Kubeflow Pipelines** will supply the orchastration to run the pipeline, while **MLRun** will supply an easy interface to define the pipeline and lunch the serving function at the end.\n",
    "\n",
    "We will show how to:\n",
    "* Run remote functions from notebooks using `code_to_function`\n",
    "* Run saved functions from our DB using `import_function`\n",
    "* How to define and lunch a Kubeflow Pipeline\n",
    "* How to access the DB from the code and list the pipeline's entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_function, code_to_function, get_run_db, mount_v3io, mlconf, new_model_server, v3io_cred, import_function\n",
    "import os\n",
    " \n",
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/User/mlrun/examples'\n",
    "images_path = os.path.join(base_dir, 'images')\n",
    "model_name = 'cat_vs_dog_v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and define ML functions for our pipeline (utils, training, serving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `code_to_function` we parse the given python file and build a function from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f1bb2a61f98>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data import and labeling \n",
    "utilsfn = code_to_function(name='file_utils', filename='../py/utils.py',\n",
    "                           image='mlrun/mlrun:latest', kind='job')\n",
    "utilsfn.apply(mount_v3io())\n",
    "#utilsfn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `import_function` we import the horovod training function from our DB.  \n",
    "As we can see, all the function deployment parameters were saved, like Replicas, GPU Configuration, Mounts, Runtime and the code source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'mpijob',\n",
       " 'metadata': {'name': 'horovod-trainer',\n",
       "  'tag': 'latest',\n",
       "  'project': 'default',\n",
       "  'updated': 'Thu, 06 Feb 2020 20:23:59 GMT'},\n",
       " 'spec': {'command': '/User/mlrun-demos/demos/image_classification/horovod-training.py',\n",
       "  'args': [],\n",
       "  'image': 'mlrun/mpijob:latest',\n",
       "  'volumes': [{'flexVolume': {'driver': 'v3io/fuse',\n",
       "     'options': {'accessKey': '35a024a5-c3ee-4fdd-82f8-b7a4fc669002',\n",
       "      'container': 'users',\n",
       "      'subPath': '/admin'}},\n",
       "    'name': 'v3io'}],\n",
       "  'volume_mounts': [{'mountPath': '/User', 'name': 'v3io'}],\n",
       "  'env': [{'name': 'V3IO_API', 'value': 'v3io-webapi.default-tenant.svc:8081'},\n",
       "   {'name': 'V3IO_USERNAME', 'value': 'admin'},\n",
       "   {'name': 'V3IO_ACCESS_KEY',\n",
       "    'value': '35a024a5-c3ee-4fdd-82f8-b7a4fc669002'}],\n",
       "  'description': '',\n",
       "  'replicas': 4,\n",
       "  'image_pull_policy': 'Always',\n",
       "  'build': {'commands': []}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the training function object from MLRun DB\n",
    "trainer_fn = import_function('db://horovod-trainer')\n",
    "# trainer_fn.deploy()\n",
    "trainer_fn.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `filename=<jupyter notebook file>` in the `new_model_server` we parse the given Jupyter Notebook and build our model server from it.\n",
    "\n",
    "> All the annotations given in the notebook will be parsed and saved to the function normally\n",
    "\n",
    "The model server will deploy the model given under `models={<model_name>:<model_file_path>}` as `model_class=<model_class_name>` .  \n",
    "Just like any other MLRun function we can set our environment variables, workers and add mounts.\n",
    "\n",
    "The model server will provide us with a `/<model_name>/predict` endpoint where we can query the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f1bb2759c88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference function\n",
    "inference_function = new_model_server('tf-images-server', \n",
    "                                      filename='./nuclio-serving-tf-images.ipynb',\n",
    "                                      model_class='TFModel')\n",
    "inference_function.with_http(workers=2)\n",
    "inference_function.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we define the Kubeflow Pipeline to run our process.  \n",
    "MLRun helps us doing that by requiring us to only add `<fn>.as_step()` in order to turn our functions to a pipeline step for kubeflow.  All the parameters and inputs can be then set regularly and will be deployed as defined in the pipeline.  \n",
    "\n",
    "The pipeline order is defined by the following:\n",
    "* We can specify `<fn>.after(<previous fn>)`\n",
    "* We can specify that a function has a parameter or input, taken from a previous function.  \n",
    "  Ex: `models={'cat_vs_dog_v1': train.outputs['model']}` in the inference function definition, taking the model file from the training function.\n",
    "  \n",
    "Notice that you need to `log_artifact` in your function and write it's name in the function's `outputs` parameter to expose it to the pipeline for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_path = 'v3io:///users/admin/mlrun/kfp/{{workflow.uid}}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='Image classification training pipeline',\n",
    "    description='Shows how to use mlrun with horovod.'\n",
    ")\n",
    "def hvd_pipeline(\n",
    "    image_archive=      'http://iguazio-sample-data.s3.amazonaws.com/catsndogs.zip',\n",
    "    images_path =       '/User/mlrun/examples/images', \n",
    "    source_dir=         '/User/mlrun/examples/images/cats_n_dogs',\n",
    "    checkpoints_dir=    '/User/mlrun/examples/checkpoints',\n",
    "    model_path=         '/User/mlrun/examples/models/cats_n_dogs.h5',\n",
    "    model_name=         'cat_vs_dog_v1'\n",
    "):\n",
    "    open_archive = utilsfn.as_step(name='download', handler='open_archive',\n",
    "                                   out_path=images_path, \n",
    "                                   params={'target_dir': images_path},\n",
    "                                   inputs={'archive_url': image_archive},\n",
    "                                   outputs=['content']).apply(mount_v3io())\n",
    "              \n",
    "    label = utilsfn.as_step(name='label', handler='categories_map_builder',\n",
    "                            out_path=images_path,\n",
    "                            params={'source_dir': source_dir}, \n",
    "                            outputs=['categories_map', 'file_categories']).apply(mount_v3io()).after(open_archive)\n",
    "    \n",
    "    train = trainer_fn.as_step(name='train', \n",
    "                               params = {'epochs' : 3,\n",
    "                                         'checkpoints_dir' : checkpoints_dir,\n",
    "                                         'model_path' : model_path,\n",
    "                                         'data_path' : source_dir},\n",
    "                               inputs = {'categories_map': label.outputs['categories_map'],\n",
    "                                         'file_categories': label.outputs['file_categories']},                               \n",
    "                               outputs=['model']).apply(v3io_cred())\n",
    "\n",
    "    # deploy the model using nuclio functions\n",
    "    deploy = inference_function.deploy_step(project = 'nuclio-serving', models={model_name: train.outputs['model']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug generate the pipeline dsl\n",
    "kfp.compiler.Compiler().compile(hvd_pipeline, 'hvd_pipeline.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.kayozzwcgoud.iguazio-cd2.com/pipelines//#/experiments/details/f47772b1-fa1d-4c29-bfd1-ed6b3596cae4\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.kayozzwcgoud.iguazio-cd2.com/pipelines//#/runs/details/74db667a-fce4-4e93-9a05-0555731e8dea\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client(namespace='default-tenant')\n",
    "arguments = {}\n",
    "run_result = client.create_run_from_pipeline_func(hvd_pipeline, arguments, experiment_name='horovod1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the run db \n",
    "db = get_run_db().connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the DB with filter on workflow ID (only show this workflow) \n",
    "db.list_runs('', labels=f'workflow={run_result.run_id}').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
